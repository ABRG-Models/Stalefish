# Reading the HDF5 data

This directory contains some help on getting access to the data file
written out by the program.

The data is written in "Hierarchical Data Format, version 5", or just
"HDF5", which is a widely-used, standard format.

There are several ways to read HDF5 files and get access to the data
they store, and you can choose the one that suits you best. Here's an
incomplete list:

* Python - using the h5py module or pandas.read_hdf()
* MATLAB - using the hdf5read function
* GNU Octave - It's as easy as "load myhdf5.h5"
* HDFView: [Download HDFView](https://portal.hdfgroup.org/display/support/Download+HDFView)
* The h5dump command, which can lead to a lot of text output, but it's
  all human readable.
* C or C++ - HDF5 has a C API, and morphologica has a wrapper class
  around the C API (See morph::HdfData).

I tend to use GNU Octave for a quick look at a file, and python or
morph::HdfData for analysis. Look at the README.md files in the octave
and python subdirectories for examples.

## Data layout

While the HDF5 format is standard, the meaning of the data is specific to
the Stalefish application, so here's some reference information on
what you'll find in the HDF5 files.

### Root level

At the root level of the data file, you'll find lots of 'frames'. Each
frame contains the information about a single brain slice preparation. It
includes the filename of the image that was used, the points that the
user set to define the curve, the parameters for the gene expression
sampling bins and so
on. So, at the root level there are several data structures called
**Frame001**, **Frame002** and so on, as well as an integer *nframes*
which makes it easy to write a loop through all the frames in an
analysis script.

 * **Frame001**, **Frame002** etc: One Frame object for each brain slice.
 * **nframes**: The number of Frame objects in this data file.
 * **map**: Contains the final 2D expression map, generated by
   unwrapping the 3D reconstruction. The data in here is constructed
   from data in Frame001, etc and is provided as a convenience.
 * **config**: Contains a copy of the JSON configuration file which
   was used to create the initial Stalefish project.

### Frame level

Each **FrameNNN** contains a number of objects, most of which are
'sub-containers' which hold the information you'll need for your
analysis. The **class** object contains data which wouldn't typically be
required for analysis, but which enables the application to re-open a
project.

 * **FrameNNN/nboxes**: Contains the number of sample boxes (the yellow boxes
   arranged around the curve) in this frame.

 * **FrameNNN/nfreehand**: Contains the number of freehand drawn loops in this
   frame.

 * **FrameNNN/unit_normals**: Array containing the 2D unit normal vectors on the
   fitted curve.

#### FrameNNN/class

**class** is structure containing all the data required to re-open a
Stalefish project, some of which may be useful in analysis. See below
for a description of the objects which you will find inside class.

Each frame's class object contains:

 * **P**: Coordinates of the user points which have not yet be 'finalised'
  as a complete 'curve set'. These are the points which appear green
  in the application.
 * **PP000**, **PP001**, etc: 2D Coordinate 'curve sets' - the red and blue
  'user points'.
 * **PP_n**: The number of PP* curve sets.
 * **binA**: The distance from the fitted curve, along a normal to the curve, at which the bins start.
 * **binB**: The distance from the fitted curve, along a normal to the curve, at which the bins stop.
 * **filename**: The name of the image file of the brain slice
 * **flags**: Some flags which specify how the application should
  visualise the curve
 * **idx**: The frame's index number
 * **layer_x**: The position of the brain slice along the x axis.
 * **nBinsTarg**: The number of bins along the fitted curve.
 * **pixels_per_mm**: The scale for the brain slice image.
 * **polyOrder**: The order of the polynomial curve, if used.
 * **pp_idx**: A state variable for the program (not useful for analysis).
 * **thickness**: The thickness of the brain slice, as copied from the
  JSON config file.
 * **FLE000**, **FLE001**, etc: 2D coordinates of the pixels enclosed in each
  freehand loop.
 * **FLB000**, **FLB001**, etc: 2D coordinates of the pixels which make up the
  boundary of each freehand loop. Stored only so that the boundary can
  be drawn in the user interface. The boundary pixels are not used when
  computing signal inside the boundary.
 * **FLE_n**: The number of freehand loops

### Location information

The following set of frame objects all contain location
information. The four containers refer to location information in four
possible frames of reference.

 * **FrameNNN/pixels**: In here, all coordinates represent original
     location information in screen pixels.

 * **FrameNNN/scaled**: In **scaled**, location information is given in
     mm, scaled from screen pixels. No transformation is applied to
     individual frames.

 * **FrameNNN/autoalign**: Locations here are given in mm, with each
   brain slice auto-aligned with its neighbours, using the
   user-provided curve points to determine the best possible
   translation and rotation to align the slice.

 * **FrameNNN/lmalign**: Location info in mm, with each brain slice
   aligned with its neighbours making use of the user-supplied tissue
   landmarks.

#### Location objects

Each of **FrameNNN/autoalign** or **FrameNNN/lmalign** may contain:

 * **box_depth**: Contains **FrameNNN/n_boxes** array of values, for each
     sample box

 * **centre_box_index**: The index of the sample box which is on the
     designated 'centre line' (usually defined as being at some angle
     about the brain axis).

 * **computed**: A boolean. If 0, then the autoalign (or lmalign) process
     was not computed.

 * **coords**: Contains vectors of the 2D coordinates of each pixel in
     sample boxes and freehand drawn loops.

  - **coords/boxes**: Contains box0, box1, etc, containing 2D coords of
     pixels in sample boxes

  - **coords/freehand**: Contains loop0, loop1, etc, containing 2D
     coords of pixels in freehand drawn loops

 * **fitted**: A 2 by FrameNNN/nboxes matrix containing 2D coordinates
     of the FrameNNN/nboxes evenly spaced points on the Bezier curve
     created with user-supplied points.

 * **flattened**: This contains **sbox_angles**, which is an array of the
     angles (in radians) about the origin at which the surface boxes
     for this frame lie. This can be used to create a flat, two
     dimensional heatmap plot of the signal. A 'surface box' is the
     box which is a long as the corresponding sample box is wide, and
     as wide as the slice is thick. It also contains
     **sbox_linear_distance** which is takes the distance along each
     curve using the zero angle in sbox_angles as the start point for
     each linear distance.

 * **freehand**: Contains location data relating to the freehand-drawn
     loops. This may contain loop0_centroid, loop1_centroid, etc,
     giving the location of each loop. For the boundary of each loop,
     see FrameNNN/class/FBE000 etc.

 * **landmarks**: This is a two column matrix containing the 2D locations
      of the user-supplied landmark positions which are the black dots
      numbered 1, 2, etc in the user interface.

 * **sbox_centers**: 3D coordinates of the centers of the surface
    boxes. The y-z coordinates are in the plane of each brain slice;
    the x coordinate is derived from the json config file, which
    should provide a x coordinate (in mm) for each slice.

 * **sboxes**: 3D coordinates of the vertices of the surface boxes.

 * **translation**: The translation applied to this slice

 * **theta**: The rotational transformation applied to this slice after
    the *translation* was applied.

 * **alignmark_origins**: The alignment mark axis passes through the slice
   at this coordinate. User gives two alignment marks per project and
   a linear fit is made to these two.

From the list above, **FrameNNN/scaled** may contain **fitted**,
 **flattened**, **sbox_centers** and **signal**, only.

**FrameNNN/pixels** may contain **coords** and **fitted** only.

### Signal information

**FrameNNN/signal** contains both 8-bit data - the original R (or G or
 B) values from the (usually monochrome) brain slice image and also
 'post-processed' data, which has had the blurred background subtracted
 from it and been transformed linearly into the range 0 to 1.

**FrameNNN/signal/bits8** contains the 8 bit data;
 **FrameNNN/signal/postproc** contains the post processed data. Each
 of these contains **boxes** and **freehand**, inside which are lists
 of the signal values for the sample boxes and the freehand drawn
 loops.

 * **signal/*/boxes/box0**, **box1**, etc - The signal values for each pixel
   in each sample box

 * **signal/*/boxes/means** - The mean signal value for each sample box

 * **signal/*/boxes/sds** - The standard deviation value for each sample box

 * **signal/*/boxes/means_autoscaled** - The mean signal value for each
   sample box autoscaled to lie in the range [0, 1].

 * **signal/*/freehand/loop0**, **loop1**, etc - The signal values for each pixel
   in each freehand loop.

 * **signal/*/freehand/means** - The mean signal value for each freehand loop

### map

This contains the final, 2D map reconstructed from the curves in the
brain slices. The information here can also be found within the
FrameNNN objects, but it's collected together here to make it easy to
access the 2D expression map.

* **/map/x** A vector of x positions
* **/map/y_lmalign** A vector of 2D map y positions computed using landmark alignment of the slices
* **/map/y_autoalign** A vector of 2D map y positions from autoaligned slices
* **/map/means** - vector of map mean signal values
